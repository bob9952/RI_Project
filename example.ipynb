{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35a8a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9864dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_list = ['zero','one','two','three','four','five','six','seven','eight','nine','minus','plus','equal','div','decimal','times']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a171c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8a6ed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2912a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./projekat/handwritten_bolji/train\"\n",
    "train_image = []\n",
    "train_label = []\n",
    "\n",
    "for symbols_dir in os.listdir(dataset_path):\n",
    "    if symbols_dir.split()[0] in symbols_list:\n",
    "        for image in os.listdir(dataset_path + \"/\" + symbols_dir):\n",
    "            train_label.append(symbols_dir.split()[0])\n",
    "            train_image.append(dataset_path + \"/\" + symbols_dir + \"/\" + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ebeca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = \"./projekat/handwritten_bolji/eval\"\n",
    "test_image = []\n",
    "test_label = []\n",
    "\n",
    "for symbols_dir in os.listdir(eval_path):\n",
    "    if symbols_dir.split()[0] in symbols_list:\n",
    "        for image in os.listdir(eval_path + \"/\" + symbols_dir):\n",
    "            test_label.append(symbols_dir.split()[0])\n",
    "            test_image.append(eval_path + \"/\" + symbols_dir + \"/\" + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c792c4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "# laoding the images from the path\n",
    "for path in train_image:    \n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    img = np.array(img)\n",
    "    X_train.append(img)\n",
    "\n",
    "for path in test_image:    \n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, IMAGE_SIZE)\n",
    "    img = np.array(img)     \n",
    "    X_test.append(img)\n",
    "\n",
    "# creating numpy array from the images\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc98586b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (7557, 100, 100, 3)\n",
      "X_test shape:  (1010, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# normalizing the data\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5ff28ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./projekat/handwritten_bolji/train/decimal/1003.jpg\n",
      "decimal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x256ed2b4550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_image[0])\n",
    "print(train_label[0])\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2bc9fbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1010, 16)\n",
      "(7557, 16)\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array([[0] * 16 for _ in range(len(train_label))])\n",
    "\n",
    "for i, category in enumerate(train_label):\n",
    "    index = symbols_list.index(category)\n",
    "    y_train[i][index] = 1\n",
    "y_test = np.array([[0] * 16 for _ in range(len(test_label))])\n",
    "\n",
    "for i, category in enumerate(test_label):\n",
    "    index = symbols_list.index(category)\n",
    "    y_train[i][index] = 1\n",
    "\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e3763ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaaff36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8bcbaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet_v2 import ResNet50V2, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4863feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = ResNet50V2(include_top=False, weights='imagenet', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49030631",
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc6571be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1],3))\n",
    "x = transfer_model(inputs)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "outputs = keras.layers.Dense(16, activation='softmax')(x)\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13ea31bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "resnet50v2 (Functional)      (None, 4, 4, 2048)        23564800  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                32784     \n",
      "=================================================================\n",
      "Total params: 23,597,584\n",
      "Trainable params: 32,784\n",
      "Non-trainable params: 23,564,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14dfbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=keras.metrics.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c54c0271",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\keras\\engine\\training.py:1134\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1128\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cluster_coordinator \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mcoordinator\u001b[38;5;241m.\u001b[39mClusterCoordinator(\n\u001b[0;32m   1129\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), \\\n\u001b[0;32m   1132\u001b[0m      training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1133\u001b[0m   \u001b[38;5;66;03m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[1;32m-> 1134\u001b[0m   data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m      \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m      \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m      \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m      \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m      \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m   \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1151\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1383\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1382\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1138\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1135\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution_value \u001b[38;5;241m=\u001b[39m steps_per_execution\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1137\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1152\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:230\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    220\u001b[0m              x,\n\u001b[0;32m    221\u001b[0m              y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    227\u001b[0m              shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    228\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    229\u001b[0m   \u001b[38;5;28msuper\u001b[39m(TensorLikeDataAdapter, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 230\u001b[0m   x, y, sample_weights \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m   sample_weight_modes \u001b[38;5;241m=\u001b[39m broadcast_sample_weight_modes(\n\u001b[0;32m    232\u001b[0m       sample_weights, sample_weight_modes)\n\u001b[0;32m    234\u001b[0m   \u001b[38;5;66;03m# If sample_weights are not specified for an output use 1.0 as weights.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1031\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[0;32m   1029\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m-> 1031\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_numpy_and_scipy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:869\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    865\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    866\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 869\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    870\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1026\u001b[0m, in \u001b[0;36m_process_tensorlike.<locals>._convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1024\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[0;32m   1025\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mfloatx()\n\u001b[1;32m-> 1026\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_scipy_sparse(x):\n\u001b[0;32m   1028\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 206\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m    208\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m    209\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m    210\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(wrapper, args, kwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1430\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m   1367\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m   1368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m   1369\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1370\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m   1371\u001b[0m \n\u001b[0;32m   1372\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m   1429\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1430\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1431\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1436\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1434\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1435\u001b[0m   \u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1436\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1439\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1440\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1441\u001b[0m \u001b[43m      \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1561\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1562\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1563\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1566\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   1569\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     51\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m as_ref  \u001b[38;5;66;03m# Unused.\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    176\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    282\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 283\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[0;32m    286\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    307\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    105\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=16\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
